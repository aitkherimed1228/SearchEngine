# Moteur de Recherche S√©mantique pour Articles Scientifiques

Ce projet impl√©mente un **moteur de recherche s√©mantique avanc√©** destin√© √† la recommandation d'articles scientifiques. Il r√©sout un probl√®me de **Citation Matching** : √©tant donn√© un article (requ√™te), retrouver les articles qu'il cite parmi une liste de candidats, en distinguant les liens pertinents du bruit.

Le projet compare et combine des approches classiques (fr√©quentielles), neuronales (Transformers) et topologiques (Graphes).

## üéØ Objectifs

* **Recherche d'Information (IR) :** Construire un syst√®me capable de classer des documents scientifiques par pertinence s√©mantique.
* **Comparaison d'approches :** √âvaluer le gap de performance entre les m√©thodes creuses (Sparse), les repr√©sentations denses (Embeddings) et les approches structurelles (Graphes).
* **Analyse de contenu :** Comparer l'impact de l'utilisation des titres seuls par rapport √† l'utilisation combin√©e des titres et des r√©sum√©s.

## üóÇÔ∏è Dataset

Le projet s'appuie sur un corpus bibliographique r√©el :
* **Corpus :** 25 657 articles scientifiques contenant titres, r√©sum√©s et m√©tadonn√©es (auteurs).
* **Requ√™tes :** 1 000 articles sources utilis√©s comme requ√™tes.
* **V√©rit√© Terrain :** 20 950 paires annot√©es (score 0 ou 1) pour la validation et l'√©valuation des mod√®les.

## ‚öôÔ∏è M√©thodologie

Le pipeline du projet suit une complexit√© croissante √† travers trois axes majeurs :

### 1. Approche "Sparse" (Baseline)
Utilisation de m√©thodes statistiques classiques pour √©tablir une ligne de base bas√©e sur la fr√©quence des mots.
* **Bag-of-Words (BoW) :** Encodage simple via `CountVectorizer` pour construire une matrice documents-termes.
* **TF-IDF :** Pond√©ration des termes pour r√©duire l'importance des mots trop fr√©quents et valoriser les mots discriminants.
* **R√©sultat :** Capture efficace des mots-cl√©s exacts mais difficult√© √† saisir la synonymie.

### 2. Approche "Dense" (Transformers)
Utilisation de mod√®les d'√©tat de l'art pour projeter les textes dans un espace vectoriel s√©mantique (Embeddings).
* **Mod√®le :** `all-MiniLM-L6-v2` via la biblioth√®que `sentence-transformers`.
* **Strat√©gies de contenu :**
    * *Titres seuls :* Encodage rapide, focalis√© sur l'id√©e principale.
    * *Enrichi (Titre + [SEP] + R√©sum√©) :* Maximise l'information contextuelle pour une meilleure pr√©cision.
* **Similarit√© :** Utilisation de la similarit√© cosinus pour le classement des documents.



### 3. Approche Topologique (Graphes)
Exploitation de la structure relationnelle entre les documents, les mots et les auteurs.
* **Structure du Graphe :** Construction d'un graphe h√©t√©rog√®ne incluant des n≈ìuds pour les documents, les mots (filtr√©s par fr√©quence) et les auteurs.
* **Node Embeddings :** Utilisation de **Random Walks** (marches al√©atoires) et de l'algorithme **Word2Vec** (Skip-gram) pour apprendre des repr√©sentations vectorielles bas√©es sur la topologie du r√©seau.
* **Avantage :** Capture des relations de co-citation et d'expertise via les auteurs communs.

## üõ†Ô∏è Stack Technique

* **Langage :** Python 3.10
* **NLP & Embeddings :** `sentence-transformers`, `scikit-learn`, `gensim`
* **Graphes :** `networkx`
* **Manipulation de donn√©es :** `pandas`, `numpy`
* **Visualisation :** `matplotlib`

## üöÄ Installation et Ex√©cution

1. **Cloner le d√©p√¥t :**
   ```bash
   git clone https://github.com/aitkherimed1228/SearchEngine
   ```